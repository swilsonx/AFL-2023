{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af95bcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final version of model \n",
    "#Models are trained on 100% of the training data, having previously been tested using cross val and then a hold out test sample\n",
    "#Final model is saved to disk for use in scoring notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "829e189e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing basic packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from matplotlib import pyplot\n",
    "from numpy import set_printoptions\n",
    "from pickle import dump\n",
    "from pickle import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f44256a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the Dataset\n",
    "#Data from old 2019 model training, includes data from 2014 to 2019\n",
    "afl = pd.read_csv('C:\\\\Users\\\\D648007\\\\AFLdata2.csv')\n",
    "dataset = afl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84fb9ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hm_PWk_lad', 'aw_PWk_lad', 'PWk_lad_gap', 'hm_PWk_perc', 'aw_PWk_perc', 'PWk_perc_gap', 'hm_PWk_pts', 'aw_PWk_pts', 'PWk_pts_gap', 'hm_PWk_pts_stan', 'aw_PWk_pts_stan', 'PWk_pts_gap_stan', 'aw_PY', 'aw_PY_perc', 'aw_2PY', 'aw_2PY_perc', 'aw_3PY', 'aw_3PY_perc', 'aw_4PY', 'aw_4PY_perc', 'aw_PY_2PY', 'aw_PY_3PY', 'aw_PY_4PY', 'aw_Pypc_2Pypc', 'aw_Pypc_3Pypc', 'aw_Pypc_4Pypc', 'PY_gap', 'PY_%_gap', '2PY_gap', '2PY_%_gap', '3PY_gap', '3PY_%_gap', '4PY_gap', '4PY_%_gap', 'aw_Dr_PY', 'aw_Dr_2PY', 'aw_Dr_3py', 'aw_Dr_4py', 'aw_Dr_Tot', 'Dr_PY_gap', 'Dr_2PY_gap', 'Dr_3PY_gap', 'Dr_4PY_gap', 'Dr_Tot_gap', 'aw_Pwk_win', 'aw_2Pwk_win', 'aw_3Pwk_win', 'aw_4Pwk_win', 'aw_win_1', 'aw_win_2', 'aw_win_3', 'aw_win_4', 'h_win_1_gap', 'h_win_2_gap', 'h_win_3_gap', 'h_win_4_gap', 'a_win_1_gap', 'a_win_2_gap', 'a_win_3_gap', 'a_win_4_gap', 'Interstate']\n"
     ]
    }
   ],
   "source": [
    "#Identify which columns have NaN (Not a Number - i.e. missing values)\n",
    "nan_values = dataset.isna()\n",
    "nan_columns = nan_values.any()\n",
    "\n",
    "columns_with_nan = dataset.columns[nan_columns].tolist()\n",
    "print(columns_with_nan)\n",
    "\n",
    "#Need to remove the NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7fe6d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get names of indexes for which column hm_score has value 0\n",
    "indexNames = dataset[ dataset['hm_score'] == 0 ].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01870046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete these row indexes from dataFrame\n",
    "dataset.drop(indexNames , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75c545af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "#Identify which columns have NaN (Not a Number - i.e. missing values)\n",
    "nan_values = dataset.isna()\n",
    "nan_columns = nan_values.any()\n",
    "\n",
    "columns_with_nan = dataset.columns[nan_columns].tolist()\n",
    "print(columns_with_nan)\n",
    "\n",
    "#Need to remove the NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1abba881",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create training dataset of features identified through feature importance testing\n",
    "dataset = dataset[[\"round\", \"hm_PWk_lad\", \"aw_PWk_lad\", \"PWk_lad_gap\", \"hm_PWk_perc\", \"aw_PWk_perc\" , \"PWk_perc_gap\", \"hm_PWk_pts\", \n",
    "                  \"aw_PWk_pts\", \"PWk_pts_gap\", \"hm_PWk_pts_stan\", \"aw_PWk_pts_stan\", \"PWk_pts_gap_stan\", \"hm_PY\" , \"hm_PY_perc\",\n",
    "                  \"aw_PY\", \"aw_PY_perc\", \"PY_gap\", \"PY_%_gap\", \"2PY_%_gap\", \"3PY_%_gap\", \"home_win\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "babbce1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Find index location of outcome metric\n",
    "dataset.columns.get_loc(\"home_win\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00c2e297",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Before splitting into an array for model fitting, save the feature names for later use\n",
    "feature_names = list(dataset.columns)\n",
    "#remove the label name 'home_win'\n",
    "del feature_names[21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "348a2c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split into X and Y for training\n",
    "#Separate the dataset into dependent (x) and independent (y) components, starting with converting to array\n",
    "array = dataset.values\n",
    "\n",
    "X = array[:, :21]\n",
    "Y = array[:, 21]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30d53161",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = [1 if x == 1 else 0 for x in Y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bbb355a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.627  1.634 -1.61  -2.322 -1.515  1.052 -1.845 -0.87   2.894  4.059\n",
      "  -1.536  1.143  1.93   1.659 -1.666 -1.637  1.282  2.36  -2.106 -1.071\n",
      "  -0.009]\n",
      " [-1.627 -1.285 -0.256  0.733  0.604  0.9   -0.229  2.217  1.71  -0.541\n",
      "   0.721  0.294 -0.299 -1.25   0.679 -0.282  1.11  -0.692 -0.308 -0.491\n",
      "  -1.235]\n",
      " [-1.627 -0.896  0.131  0.733  0.985  0.091  0.633  1.979  1.473 -0.541\n",
      "   0.548  0.125 -0.299 -0.862  1.102  0.105  0.189 -0.692  0.651 -0.654\n",
      "  -0.218]\n",
      " [-1.627  0.466 -1.029 -1.072  0.038  0.512 -0.347  1.505  2.183  0.737\n",
      "   0.2    0.634  0.32   0.495  0.054 -1.057  0.669  1.112 -0.44   1.21\n",
      "   0.5  ]\n",
      " [-1.627  0.661 -0.643 -0.933 -0.891  0.155 -0.746  0.555  1.947  1.503\n",
      "  -0.494  0.464  0.691  0.689 -0.975 -0.669  0.262  0.973 -0.884 -0.793\n",
      "  -0.918]]\n"
     ]
    }
   ],
   "source": [
    "#Scale Training data\n",
    "scaler = StandardScaler()\n",
    "rescaledX=scaler.fit_transform(X)\n",
    "\n",
    "#summarise transformed data\n",
    "set_printoptions(precision=3)\n",
    "print(rescaledX[0:5, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0b3935d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1762, 21)\n"
     ]
    }
   ],
   "source": [
    "print(rescaledX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04e6b8d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=5, max_features='log2', n_estimators=1000)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit Random Forest\n",
    "# Random Forest creates a lot of trees and then slects the most frequent class as the winning prediction.\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=1000, max_features='log2', max_depth= 5)\n",
    "rf.fit(rescaledX, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd508ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the model to disk\n",
    "\n",
    "filename = 'afl2022modelRF.sav'\n",
    "dump(rf, open(filename, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
